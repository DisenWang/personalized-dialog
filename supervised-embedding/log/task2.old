data/train-task-2.tsv (56988, 2, 120)
data/dev-task-2-500.tsv (500, 2, 120)
data/candidates.tsv (43863, 2, 120)
[INFO] 2017-05-21T00:24:58+0800: Run main with config {'epochs': 400, 'negative_cand': 100, 'save_dir': 'checkpoints/task-2/model', 'batch_size': 32, 'lr': 0.01} (train.py:76)
[INFO] 2017-05-21T00:28:38+0800: Epoch: 0; Train loss: 0.31156082109553707; Dev loss: 1.301020263671875; (train.py:98)
[INFO] 2017-05-21T00:29:51+0800: Evaluation: (48, 452, 0.096) (train.py:102)
[DEBUG] 2017-05-21T00:29:51+0800: Saving checkpoint (train.py:105)
[INFO] 2017-05-21T00:33:32+0800: Epoch: 1; Train loss: 0.29158257947683186; Dev loss: 0.7716488037109375; (train.py:98)
[INFO] 2017-05-21T00:37:12+0800: Epoch: 2; Train loss: 0.2929546966988978; Dev loss: 0.9610836181640625; (train.py:98)
[INFO] 2017-05-21T00:38:29+0800: Evaluation: (66, 434, 0.132) (train.py:102)
[DEBUG] 2017-05-21T00:38:29+0800: Saving checkpoint (train.py:105)
[INFO] 2017-05-21T00:42:09+0800: Epoch: 3; Train loss: 0.29531024009116447; Dev loss: 1.2012822265625; (train.py:98)
[INFO] 2017-05-21T00:45:51+0800: Epoch: 4; Train loss: 0.29535170888565554; Dev loss: 0.7065648193359375; (train.py:98)
[INFO] 2017-05-21T00:47:08+0800: Evaluation: (66, 434, 0.132) (train.py:102)
[DEBUG] 2017-05-21T00:47:08+0800: Saving checkpoint (train.py:105)
[INFO] 2017-05-21T00:50:49+0800: Epoch: 5; Train loss: 0.2945941329093496; Dev loss: 1.201694091796875; (train.py:98)
[INFO] 2017-05-21T00:54:30+0800: Epoch: 6; Train loss: 0.2953385637940445; Dev loss: 0.697250244140625; (train.py:98)
[INFO] 2017-05-21T00:55:44+0800: Evaluation: (62, 438, 0.124) (train.py:102)
[INFO] 2017-05-21T00:59:25+0800: Epoch: 7; Train loss: 0.2961767831510757; Dev loss: 0.39581109619140625; (train.py:98)
[INFO] 2017-05-21T01:03:05+0800: Epoch: 8; Train loss: 0.29390103647068416; Dev loss: 0.916354248046875; (train.py:98)
[INFO] 2017-05-21T01:04:23+0800: Evaluation: (63, 437, 0.126) (train.py:102)
[INFO] 2017-05-21T01:08:04+0800: Epoch: 9; Train loss: 0.2958041785201645; Dev loss: 0.8229127197265625; (train.py:98)
[INFO] 2017-05-21T01:11:46+0800: Epoch: 10; Train loss: 0.29403362592437726; Dev loss: 0.8461693725585937; (train.py:98)
[INFO] 2017-05-21T01:12:57+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-21T01:16:37+0800: Epoch: 11; Train loss: 0.2952045512512719; Dev loss: 0.302663330078125; (train.py:98)
[INFO] 2017-05-21T01:20:17+0800: Epoch: 12; Train loss: 0.29602766292895455; Dev loss: 0.6855747680664063; (train.py:98)
[INFO] 2017-05-21T01:21:34+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T01:25:14+0800: Epoch: 13; Train loss: 0.29057964322582597; Dev loss: 0.46994192504882815; (train.py:98)
[INFO] 2017-05-21T01:28:55+0800: Epoch: 14; Train loss: 0.29697597408977355; Dev loss: 0.8233102416992187; (train.py:98)
[INFO] 2017-05-21T01:30:08+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T01:33:49+0800: Epoch: 15; Train loss: 0.2965948858467597; Dev loss: 0.5829946899414062; (train.py:98)
[INFO] 2017-05-21T01:37:30+0800: Epoch: 16; Train loss: 0.29688334758547574; Dev loss: 0.709729736328125; (train.py:98)
[INFO] 2017-05-21T01:38:43+0800: Evaluation: (63, 437, 0.126) (train.py:102)
[INFO] 2017-05-21T01:42:24+0800: Epoch: 17; Train loss: 0.29655336849025093; Dev loss: 0.6135580444335937; (train.py:98)
[INFO] 2017-05-21T01:46:04+0800: Epoch: 18; Train loss: 0.2970017061300094; Dev loss: 0.860155517578125; (train.py:98)
[INFO] 2017-05-21T01:47:27+0800: Evaluation: (71, 429, 0.142) (train.py:102)
[DEBUG] 2017-05-21T01:47:27+0800: Saving checkpoint (train.py:105)
[INFO] 2017-05-21T01:51:09+0800: Epoch: 19; Train loss: 0.29838185372399906; Dev loss: 0.7592738037109374; (train.py:98)
[INFO] 2017-05-21T01:54:49+0800: Epoch: 20; Train loss: 0.3001562782889092; Dev loss: 1.433205078125; (train.py:98)
[INFO] 2017-05-21T01:56:03+0800: Evaluation: (61, 439, 0.122) (train.py:102)
[INFO] 2017-05-21T01:59:43+0800: Epoch: 21; Train loss: 0.29420963477439643; Dev loss: 0.3805355529785156; (train.py:98)
[INFO] 2017-05-21T02:03:24+0800: Epoch: 22; Train loss: 0.2971577997592247; Dev loss: 0.776003662109375; (train.py:98)
[INFO] 2017-05-21T02:04:41+0800: Evaluation: (64, 436, 0.128) (train.py:102)
[INFO] 2017-05-21T02:08:21+0800: Epoch: 23; Train loss: 0.2955497421648523; Dev loss: 0.8887421875; (train.py:98)
[INFO] 2017-05-21T02:12:02+0800: Epoch: 24; Train loss: 0.3017366070799857; Dev loss: 0.797367431640625; (train.py:98)
[INFO] 2017-05-21T02:13:14+0800: Evaluation: (51, 449, 0.102) (train.py:102)
[INFO] 2017-05-21T02:16:54+0800: Epoch: 25; Train loss: 0.2978623292172229; Dev loss: 0.6405509033203125; (train.py:98)
[INFO] 2017-05-21T02:20:35+0800: Epoch: 26; Train loss: 0.3045149667397656; Dev loss: 0.76393359375; (train.py:98)
[INFO] 2017-05-21T02:21:53+0800: Evaluation: (70, 430, 0.14) (train.py:102)
[INFO] 2017-05-21T02:25:34+0800: Epoch: 27; Train loss: 0.2982289672035256; Dev loss: 0.4174381408691406; (train.py:98)
[INFO] 2017-05-21T02:29:17+0800: Epoch: 28; Train loss: 0.3006774221298216; Dev loss: 0.729039794921875; (train.py:98)
[INFO] 2017-05-21T02:30:33+0800: Evaluation: (61, 439, 0.122) (train.py:102)
[INFO] 2017-05-21T02:34:12+0800: Epoch: 29; Train loss: 0.2980954982905163; Dev loss: 0.822307373046875; (train.py:98)
[INFO] 2017-05-21T02:37:52+0800: Epoch: 30; Train loss: 0.2969972203467903; Dev loss: 0.9471737060546875; (train.py:98)
[INFO] 2017-05-21T02:39:10+0800: Evaluation: (70, 430, 0.14) (train.py:102)
[INFO] 2017-05-21T02:42:50+0800: Epoch: 31; Train loss: 0.2992397633654819; Dev loss: 0.5734301147460937; (train.py:98)
[INFO] 2017-05-21T02:46:30+0800: Epoch: 32; Train loss: 0.30385569604915325; Dev loss: 1.0219052124023438; (train.py:98)
[INFO] 2017-05-21T02:47:52+0800: Evaluation: (73, 427, 0.146) (train.py:102)
[DEBUG] 2017-05-21T02:47:52+0800: Saving checkpoint (train.py:105)
[INFO] 2017-05-21T02:51:34+0800: Epoch: 33; Train loss: 0.2952937596378729; Dev loss: 0.8257967529296875; (train.py:98)
[INFO] 2017-05-21T02:55:15+0800: Epoch: 34; Train loss: 0.3003579991587303; Dev loss: 0.6752918090820312; (train.py:98)
[INFO] 2017-05-21T02:56:26+0800: Evaluation: (48, 452, 0.096) (train.py:102)
[INFO] 2017-05-21T03:00:06+0800: Epoch: 35; Train loss: 0.3013358717634236; Dev loss: 0.30997991943359376; (train.py:98)
[INFO] 2017-05-21T03:03:47+0800: Epoch: 36; Train loss: 0.3028235850144116; Dev loss: 1.19444384765625; (train.py:98)
[INFO] 2017-05-21T03:05:01+0800: Evaluation: (51, 449, 0.102) (train.py:102)
[INFO] 2017-05-21T03:08:42+0800: Epoch: 37; Train loss: 0.3036387784472795; Dev loss: 0.31524703979492186; (train.py:98)
[INFO] 2017-05-21T03:12:22+0800: Epoch: 38; Train loss: 0.301382390108128; Dev loss: 0.698042236328125; (train.py:98)
[INFO] 2017-05-21T03:13:36+0800: Evaluation: (58, 442, 0.116) (train.py:102)
[INFO] 2017-05-21T03:17:16+0800: Epoch: 39; Train loss: 0.2993741414672285; Dev loss: 0.5116478271484375; (train.py:98)
[INFO] 2017-05-21T03:20:56+0800: Epoch: 40; Train loss: 0.3002397627606018; Dev loss: 0.9616319580078125; (train.py:98)
[INFO] 2017-05-21T03:22:15+0800: Evaluation: (70, 430, 0.14) (train.py:102)
[INFO] 2017-05-21T03:25:55+0800: Epoch: 41; Train loss: 0.30297298390694904; Dev loss: 0.6256187744140626; (train.py:98)
[INFO] 2017-05-21T03:29:36+0800: Epoch: 42; Train loss: 0.3010828909543317; Dev loss: 0.754047119140625; (train.py:98)
[INFO] 2017-05-21T03:30:59+0800: Evaluation: (78, 422, 0.156) (train.py:102)
[DEBUG] 2017-05-21T03:30:59+0800: Saving checkpoint (train.py:105)
[INFO] 2017-05-21T03:34:40+0800: Epoch: 43; Train loss: 0.2944825828506496; Dev loss: 0.9023905029296875; (train.py:98)
[INFO] 2017-05-21T03:38:21+0800: Epoch: 44; Train loss: 0.3066309531349883; Dev loss: 0.8820079956054687; (train.py:98)
[INFO] 2017-05-21T03:39:42+0800: Evaluation: (76, 424, 0.152) (train.py:102)
[INFO] 2017-05-21T03:43:23+0800: Epoch: 45; Train loss: 0.30296157775426935; Dev loss: 0.837726806640625; (train.py:98)
[INFO] 2017-05-21T03:47:03+0800: Epoch: 46; Train loss: 0.30577804211130805; Dev loss: 0.8305494384765625; (train.py:98)
[INFO] 2017-05-21T03:48:17+0800: Evaluation: (55, 445, 0.11) (train.py:102)
[INFO] 2017-05-21T03:51:56+0800: Epoch: 47; Train loss: 0.29586196603647663; Dev loss: 0.51347119140625; (train.py:98)
[INFO] 2017-05-21T03:55:37+0800: Epoch: 48; Train loss: 0.30425952875668116; Dev loss: 0.860771484375; (train.py:98)
[INFO] 2017-05-21T03:56:53+0800: Evaluation: (61, 439, 0.122) (train.py:102)
[INFO] 2017-05-21T04:00:34+0800: Epoch: 49; Train loss: 0.2999107535729195; Dev loss: 0.46330841064453127; (train.py:98)
[INFO] 2017-05-21T04:04:13+0800: Epoch: 50; Train loss: 0.30078199660370314; Dev loss: 0.73283203125; (train.py:98)
[INFO] 2017-05-21T04:05:30+0800: Evaluation: (53, 447, 0.106) (train.py:102)
[INFO] 2017-05-21T04:09:11+0800: Epoch: 51; Train loss: 0.3002592691514275; Dev loss: 0.502798583984375; (train.py:98)
[INFO] 2017-05-21T04:12:52+0800: Epoch: 52; Train loss: 0.3048317006896057; Dev loss: 1.0400443115234375; (train.py:98)
[INFO] 2017-05-21T04:14:04+0800: Evaluation: (50, 450, 0.1) (train.py:102)
[INFO] 2017-05-21T04:17:46+0800: Epoch: 53; Train loss: 0.3066342605906194; Dev loss: 0.47219281005859376; (train.py:98)
[INFO] 2017-05-21T04:21:27+0800: Epoch: 54; Train loss: 0.30439526701127867; Dev loss: 0.7580648193359375; (train.py:98)
[INFO] 2017-05-21T04:22:40+0800: Evaluation: (65, 435, 0.13) (train.py:102)
[INFO] 2017-05-21T04:26:22+0800: Epoch: 55; Train loss: 0.3009017271806867; Dev loss: 0.9211409301757812; (train.py:98)
[INFO] 2017-05-21T04:30:05+0800: Epoch: 56; Train loss: 0.3020082422365756; Dev loss: 0.7799681396484375; (train.py:98)
[INFO] 2017-05-21T04:31:20+0800: Evaluation: (61, 439, 0.122) (train.py:102)
[INFO] 2017-05-21T04:34:59+0800: Epoch: 57; Train loss: 0.29963517088560704; Dev loss: 0.6366427001953125; (train.py:98)
[INFO] 2017-05-21T04:38:39+0800: Epoch: 58; Train loss: 0.30223799763920844; Dev loss: 1.272333251953125; (train.py:98)
[INFO] 2017-05-21T04:39:56+0800: Evaluation: (65, 435, 0.13) (train.py:102)
[INFO] 2017-05-21T04:43:36+0800: Epoch: 59; Train loss: 0.301387520412624; Dev loss: 1.0652147216796874; (train.py:98)
[INFO] 2017-05-21T04:47:18+0800: Epoch: 60; Train loss: 0.2977270642047369; Dev loss: 1.27018505859375; (train.py:98)
[INFO] 2017-05-21T04:48:34+0800: Evaluation: (63, 437, 0.126) (train.py:102)
[INFO] 2017-05-21T04:52:14+0800: Epoch: 61; Train loss: 0.3029808809535896; Dev loss: 0.7128567504882812; (train.py:98)
[INFO] 2017-05-21T04:55:56+0800: Epoch: 62; Train loss: 0.3026610791708008; Dev loss: 0.923863037109375; (train.py:98)
[INFO] 2017-05-21T04:57:12+0800: Evaluation: (67, 433, 0.134) (train.py:102)
[INFO] 2017-05-21T05:00:52+0800: Epoch: 63; Train loss: 0.3045576028910507; Dev loss: 0.36079959106445314; (train.py:98)
[INFO] 2017-05-21T05:04:33+0800: Epoch: 64; Train loss: 0.30487551306790484; Dev loss: 1.280009521484375; (train.py:98)
[INFO] 2017-05-21T05:05:47+0800: Evaluation: (68, 432, 0.136) (train.py:102)
[INFO] 2017-05-21T05:09:28+0800: Epoch: 65; Train loss: 0.29922232385061803; Dev loss: 0.5811734008789062; (train.py:98)
[INFO] 2017-05-21T05:13:10+0800: Epoch: 66; Train loss: 0.30284396713790146; Dev loss: 0.7433284912109375; (train.py:98)
[INFO] 2017-05-21T05:14:23+0800: Evaluation: (54, 446, 0.108) (train.py:102)
[INFO] 2017-05-21T05:18:05+0800: Epoch: 67; Train loss: 0.30394743467683727; Dev loss: 0.649576416015625; (train.py:98)
[INFO] 2017-05-21T05:21:45+0800: Epoch: 68; Train loss: 0.3012194406055623; Dev loss: 1.201039306640625; (train.py:98)
[INFO] 2017-05-21T05:22:53+0800: Evaluation: (52, 448, 0.104) (train.py:102)
[INFO] 2017-05-21T05:26:34+0800: Epoch: 69; Train loss: 0.3015392519865412; Dev loss: 0.7456001586914063; (train.py:98)
[INFO] 2017-05-21T05:30:15+0800: Epoch: 70; Train loss: 0.29986495195057916; Dev loss: 1.045649169921875; (train.py:98)
[INFO] 2017-05-21T05:31:34+0800: Evaluation: (62, 438, 0.124) (train.py:102)
[INFO] 2017-05-21T05:35:15+0800: Epoch: 71; Train loss: 0.29748593897055237; Dev loss: 0.741837646484375; (train.py:98)
[INFO] 2017-05-21T05:38:55+0800: Epoch: 72; Train loss: 0.30791516971352045; Dev loss: 1.1238800048828126; (train.py:98)
[INFO] 2017-05-21T05:40:08+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T05:43:49+0800: Epoch: 73; Train loss: 0.30335881367796447; Dev loss: 0.7645146484375; (train.py:98)
[INFO] 2017-05-21T05:47:31+0800: Epoch: 74; Train loss: 0.3056562904631792; Dev loss: 0.894423583984375; (train.py:98)
[INFO] 2017-05-21T05:48:45+0800: Evaluation: (63, 437, 0.126) (train.py:102)
[INFO] 2017-05-21T05:52:26+0800: Epoch: 75; Train loss: 0.30472696254596693; Dev loss: 0.5269395141601563; (train.py:98)
[INFO] 2017-05-21T05:56:07+0800: Epoch: 76; Train loss: 0.300074853680869; Dev loss: 0.7293062133789062; (train.py:98)
[INFO] 2017-05-21T05:57:22+0800: Evaluation: (50, 450, 0.1) (train.py:102)
[INFO] 2017-05-21T06:01:05+0800: Epoch: 77; Train loss: 0.302572662670748; Dev loss: 1.3359273681640624; (train.py:98)
[INFO] 2017-05-21T06:04:46+0800: Epoch: 78; Train loss: 0.30352040507012545; Dev loss: 0.8916270751953125; (train.py:98)
[INFO] 2017-05-21T06:06:03+0800: Evaluation: (62, 438, 0.124) (train.py:102)
[INFO] 2017-05-21T06:09:44+0800: Epoch: 79; Train loss: 0.30382076037024147; Dev loss: 0.7055805053710937; (train.py:98)
[INFO] 2017-05-21T06:13:25+0800: Epoch: 80; Train loss: 0.2999797644386192; Dev loss: 1.139189208984375; (train.py:98)
[INFO] 2017-05-21T06:14:40+0800: Evaluation: (55, 445, 0.11) (train.py:102)
[INFO] 2017-05-21T06:18:21+0800: Epoch: 81; Train loss: 0.30321959692459116; Dev loss: 0.754362548828125; (train.py:98)
[INFO] 2017-05-21T06:22:02+0800: Epoch: 82; Train loss: 0.30096735418999127; Dev loss: 1.1730394287109376; (train.py:98)
[INFO] 2017-05-21T06:23:21+0800: Evaluation: (67, 433, 0.134) (train.py:102)
[INFO] 2017-05-21T06:27:03+0800: Epoch: 83; Train loss: 0.2990898134407209; Dev loss: 0.6375989379882813; (train.py:98)
[INFO] 2017-05-21T06:30:42+0800: Epoch: 84; Train loss: 0.30625176064928755; Dev loss: 0.837648681640625; (train.py:98)
[INFO] 2017-05-21T06:32:00+0800: Evaluation: (72, 428, 0.144) (train.py:102)
[INFO] 2017-05-21T06:35:41+0800: Epoch: 85; Train loss: 0.3057771297730293; Dev loss: 0.708518310546875; (train.py:98)
[INFO] 2017-05-21T06:39:23+0800: Epoch: 86; Train loss: 0.3023910887264677; Dev loss: 0.7858203125; (train.py:98)
[INFO] 2017-05-21T06:40:38+0800: Evaluation: (60, 440, 0.12) (train.py:102)
[INFO] 2017-05-21T06:44:20+0800: Epoch: 87; Train loss: 0.30262042580792975; Dev loss: 1.0587391357421876; (train.py:98)
[INFO] 2017-05-21T06:47:59+0800: Epoch: 88; Train loss: 0.30361593929012726; Dev loss: 0.547626708984375; (train.py:98)
[INFO] 2017-05-21T06:49:16+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T06:52:57+0800: Epoch: 89; Train loss: 0.30113619095556093; Dev loss: 0.5251728515625; (train.py:98)
[INFO] 2017-05-21T06:56:38+0800: Epoch: 90; Train loss: 0.30701207521314083; Dev loss: 0.8423890380859375; (train.py:98)
[INFO] 2017-05-21T06:57:54+0800: Evaluation: (58, 442, 0.116) (train.py:102)
[INFO] 2017-05-21T07:01:36+0800: Epoch: 91; Train loss: 0.29899845297407185; Dev loss: 1.361957275390625; (train.py:98)
[INFO] 2017-05-21T07:05:17+0800: Epoch: 92; Train loss: 0.3048128392732928; Dev loss: 0.7815079956054688; (train.py:98)
[INFO] 2017-05-21T07:06:31+0800: Evaluation: (74, 426, 0.148) (train.py:102)
[INFO] 2017-05-21T07:10:11+0800: Epoch: 93; Train loss: 0.3033341133076595; Dev loss: 0.35581744384765623; (train.py:98)
[INFO] 2017-05-21T07:13:50+0800: Epoch: 94; Train loss: 0.3070934218669344; Dev loss: 1.26762255859375; (train.py:98)
[INFO] 2017-05-21T07:15:08+0800: Evaluation: (64, 436, 0.128) (train.py:102)
[INFO] 2017-05-21T07:18:49+0800: Epoch: 95; Train loss: 0.3003538452896306; Dev loss: 0.6829598999023437; (train.py:98)
[INFO] 2017-05-21T07:22:29+0800: Epoch: 96; Train loss: 0.30372780988719433; Dev loss: 1.1755279541015624; (train.py:98)
[INFO] 2017-05-21T07:23:44+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T07:27:26+0800: Epoch: 97; Train loss: 0.30366032184524616; Dev loss: 0.6977720947265625; (train.py:98)
[INFO] 2017-05-21T07:31:07+0800: Epoch: 98; Train loss: 0.3006373429177578; Dev loss: 0.957474609375; (train.py:98)
[INFO] 2017-05-21T07:32:23+0800: Evaluation: (64, 436, 0.128) (train.py:102)
[INFO] 2017-05-21T07:36:03+0800: Epoch: 99; Train loss: 0.30348112230953317; Dev loss: 0.5308837280273437; (train.py:98)
[INFO] 2017-05-21T07:39:43+0800: Epoch: 100; Train loss: 0.3032686038436289; Dev loss: 1.0082847900390626; (train.py:98)
[INFO] 2017-05-21T07:41:00+0800: Evaluation: (67, 433, 0.134) (train.py:102)
[INFO] 2017-05-21T07:44:42+0800: Epoch: 101; Train loss: 0.30116633644740004; Dev loss: 0.91455859375; (train.py:98)
[INFO] 2017-05-21T07:48:24+0800: Epoch: 102; Train loss: 0.30238736690289186; Dev loss: 1.2506854248046875; (train.py:98)
[INFO] 2017-05-21T07:49:41+0800: Evaluation: (58, 442, 0.116) (train.py:102)
[INFO] 2017-05-21T07:53:21+0800: Epoch: 103; Train loss: 0.3020648554700176; Dev loss: 0.90629833984375; (train.py:98)
[INFO] 2017-05-21T07:57:00+0800: Epoch: 104; Train loss: 0.3084569229146261; Dev loss: 1.110120361328125; (train.py:98)
[INFO] 2017-05-21T07:58:09+0800: Evaluation: (54, 446, 0.108) (train.py:102)
[INFO] 2017-05-21T08:01:51+0800: Epoch: 105; Train loss: 0.3004179665613726; Dev loss: 1.0565023193359375; (train.py:98)
[INFO] 2017-05-21T08:05:32+0800: Epoch: 106; Train loss: 0.30211589459343013; Dev loss: 0.7467410888671875; (train.py:98)
[INFO] 2017-05-21T08:06:45+0800: Evaluation: (57, 443, 0.114) (train.py:102)
[INFO] 2017-05-21T08:10:25+0800: Epoch: 107; Train loss: 0.3000916778238527; Dev loss: 0.5028775634765625; (train.py:98)
[INFO] 2017-05-21T08:14:07+0800: Epoch: 108; Train loss: 0.3029190798136743; Dev loss: 0.7334895629882813; (train.py:98)
[INFO] 2017-05-21T08:15:17+0800: Evaluation: (53, 447, 0.106) (train.py:102)
[INFO] 2017-05-21T08:19:00+0800: Epoch: 109; Train loss: 0.30292976819794243; Dev loss: 0.6054474487304687; (train.py:98)
[INFO] 2017-05-21T08:22:41+0800: Epoch: 110; Train loss: 0.3060669972466102; Dev loss: 0.7480821533203125; (train.py:98)
[INFO] 2017-05-21T08:23:58+0800: Evaluation: (62, 438, 0.124) (train.py:102)
[INFO] 2017-05-21T08:27:39+0800: Epoch: 111; Train loss: 0.30228189433683217; Dev loss: 1.09108349609375; (train.py:98)
[INFO] 2017-05-21T08:31:20+0800: Epoch: 112; Train loss: 0.30775414977274423; Dev loss: 0.6899521484375; (train.py:98)
[INFO] 2017-05-21T08:32:30+0800: Evaluation: (58, 442, 0.116) (train.py:102)
[INFO] 2017-05-21T08:36:12+0800: Epoch: 113; Train loss: 0.30133901896095683; Dev loss: 0.6028338623046875; (train.py:98)
[INFO] 2017-05-21T08:39:53+0800: Epoch: 114; Train loss: 0.3061883907227409; Dev loss: 1.16839111328125; (train.py:98)
[INFO] 2017-05-21T08:41:11+0800: Evaluation: (64, 436, 0.128) (train.py:102)
[INFO] 2017-05-21T08:44:51+0800: Epoch: 115; Train loss: 0.30261818139214663; Dev loss: 0.6718193969726562; (train.py:98)
[INFO] 2017-05-21T08:48:31+0800: Epoch: 116; Train loss: 0.30689558448162724; Dev loss: 0.977868408203125; (train.py:98)
[INFO] 2017-05-21T08:49:46+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T08:53:28+0800: Epoch: 117; Train loss: 0.3054399737078376; Dev loss: 0.7325689697265625; (train.py:98)
[INFO] 2017-05-21T08:57:09+0800: Epoch: 118; Train loss: 0.30372360252855496; Dev loss: 0.7763591918945313; (train.py:98)
[INFO] 2017-05-21T08:58:25+0800: Evaluation: (57, 443, 0.114) (train.py:102)
[INFO] 2017-05-21T09:02:05+0800: Epoch: 119; Train loss: 0.3048709343986993; Dev loss: 0.6440181884765624; (train.py:98)
[INFO] 2017-05-21T09:05:46+0800: Epoch: 120; Train loss: 0.30094762752841425; Dev loss: 0.9284296264648437; (train.py:98)
[INFO] 2017-05-21T09:06:57+0800: Evaluation: (58, 442, 0.116) (train.py:102)
[INFO] 2017-05-21T09:10:38+0800: Epoch: 121; Train loss: 0.3029844932739345; Dev loss: 0.79353076171875; (train.py:98)
[INFO] 2017-05-21T09:14:18+0800: Epoch: 122; Train loss: 0.30011451495189184; Dev loss: 0.5874636840820312; (train.py:98)
[INFO] 2017-05-21T09:15:30+0800: Evaluation: (61, 439, 0.122) (train.py:102)
[INFO] 2017-05-21T09:19:12+0800: Epoch: 123; Train loss: 0.30364055972715154; Dev loss: 0.3499830017089844; (train.py:98)
[INFO] 2017-05-21T09:22:52+0800: Epoch: 124; Train loss: 0.3049315962703901; Dev loss: 0.8172916259765625; (train.py:98)
[INFO] 2017-05-21T09:24:07+0800: Evaluation: (39, 461, 0.078) (train.py:102)
[INFO] 2017-05-21T09:27:48+0800: Epoch: 125; Train loss: 0.30296551077508227; Dev loss: 0.6015507202148438; (train.py:98)
[INFO] 2017-05-21T09:31:30+0800: Epoch: 126; Train loss: 0.30227639069478734; Dev loss: 1.0119059448242187; (train.py:98)
[INFO] 2017-05-21T09:32:47+0800: Evaluation: (66, 434, 0.132) (train.py:102)
[INFO] 2017-05-21T09:36:28+0800: Epoch: 127; Train loss: 0.3037472521760664; Dev loss: 1.254243896484375; (train.py:98)
[INFO] 2017-05-21T09:40:09+0800: Epoch: 128; Train loss: 0.3079806803575339; Dev loss: 0.915936279296875; (train.py:98)
[INFO] 2017-05-21T09:41:29+0800: Evaluation: (72, 428, 0.144) (train.py:102)
[INFO] 2017-05-21T09:45:09+0800: Epoch: 129; Train loss: 0.30128089547725123; Dev loss: 0.26775418090820313; (train.py:98)
[INFO] 2017-05-21T09:48:51+0800: Epoch: 130; Train loss: 0.3086657731603219; Dev loss: 1.4414083251953125; (train.py:98)
[INFO] 2017-05-21T09:50:02+0800: Evaluation: (54, 446, 0.108) (train.py:102)
[INFO] 2017-05-21T09:53:44+0800: Epoch: 131; Train loss: 0.3068805490651511; Dev loss: 0.53336474609375; (train.py:98)
[INFO] 2017-05-21T09:57:26+0800: Epoch: 132; Train loss: 0.3087323157674342; Dev loss: 1.184172607421875; (train.py:98)
[INFO] 2017-05-21T09:58:43+0800: Evaluation: (72, 428, 0.144) (train.py:102)
[INFO] 2017-05-21T10:02:24+0800: Epoch: 133; Train loss: 0.3084120662938338; Dev loss: 0.7016569213867188; (train.py:98)
[INFO] 2017-05-21T10:06:05+0800: Epoch: 134; Train loss: 0.309640126225688; Dev loss: 1.1526514892578126; (train.py:98)
[INFO] 2017-05-21T10:07:23+0800: Evaluation: (58, 442, 0.116) (train.py:102)
[INFO] 2017-05-21T10:11:04+0800: Epoch: 135; Train loss: 0.30640225171241514; Dev loss: 0.44875006103515624; (train.py:98)
[INFO] 2017-05-21T10:14:43+0800: Epoch: 136; Train loss: 0.3061518691459516; Dev loss: 0.7956209716796875; (train.py:98)
[INFO] 2017-05-21T10:15:59+0800: Evaluation: (60, 440, 0.12) (train.py:102)
[INFO] 2017-05-21T10:19:39+0800: Epoch: 137; Train loss: 0.305682449492735; Dev loss: 0.8392030029296875; (train.py:98)
[INFO] 2017-05-21T10:23:20+0800: Epoch: 138; Train loss: 0.30838038763749875; Dev loss: 0.7597015380859375; (train.py:98)
[INFO] 2017-05-21T10:24:36+0800: Evaluation: (58, 442, 0.116) (train.py:102)
[INFO] 2017-05-21T10:28:16+0800: Epoch: 139; Train loss: 0.2980520813721381; Dev loss: 0.4780186767578125; (train.py:98)
[INFO] 2017-05-21T10:31:55+0800: Epoch: 140; Train loss: 0.3099384428244246; Dev loss: 0.8125377807617188; (train.py:98)
[INFO] 2017-05-21T10:33:08+0800: Evaluation: (63, 437, 0.126) (train.py:102)
[INFO] 2017-05-21T10:36:49+0800: Epoch: 141; Train loss: 0.3092299131700568; Dev loss: 1.034221923828125; (train.py:98)
[INFO] 2017-05-21T10:40:31+0800: Epoch: 142; Train loss: 0.3046785853787979; Dev loss: 1.1245731201171876; (train.py:98)
[INFO] 2017-05-21T10:41:42+0800: Evaluation: (53, 447, 0.106) (train.py:102)
[INFO] 2017-05-21T10:45:22+0800: Epoch: 143; Train loss: 0.3056767824355042; Dev loss: 0.8668494262695312; (train.py:98)
[INFO] 2017-05-21T10:49:03+0800: Epoch: 144; Train loss: 0.30758862484007077; Dev loss: 0.802421142578125; (train.py:98)
[INFO] 2017-05-21T10:50:19+0800: Evaluation: (55, 445, 0.11) (train.py:102)
[INFO] 2017-05-21T10:53:59+0800: Epoch: 145; Train loss: 0.3037454008253704; Dev loss: 0.77927685546875; (train.py:98)
[INFO] 2017-05-21T10:57:41+0800: Epoch: 146; Train loss: 0.31065971649883156; Dev loss: 0.6677342529296875; (train.py:98)
[INFO] 2017-05-21T10:58:55+0800: Evaluation: (51, 449, 0.102) (train.py:102)
[INFO] 2017-05-21T11:02:36+0800: Epoch: 147; Train loss: 0.3033328676315658; Dev loss: 0.946343994140625; (train.py:98)
[INFO] 2017-05-21T11:06:16+0800: Epoch: 148; Train loss: 0.30838471537763384; Dev loss: 0.67918896484375; (train.py:98)
[INFO] 2017-05-21T11:07:32+0800: Evaluation: (57, 443, 0.114) (train.py:102)
[INFO] 2017-05-21T11:11:13+0800: Epoch: 149; Train loss: 0.3071804117383449; Dev loss: 0.6127999267578125; (train.py:98)
[INFO] 2017-05-21T11:14:52+0800: Epoch: 150; Train loss: 0.31093642191715193; Dev loss: 1.2909285888671875; (train.py:98)
[INFO] 2017-05-21T11:16:02+0800: Evaluation: (40, 460, 0.08) (train.py:102)
[INFO] 2017-05-21T11:19:43+0800: Epoch: 151; Train loss: 0.3025317301982421; Dev loss: 0.33685028076171875; (train.py:98)
[INFO] 2017-05-21T11:23:23+0800: Epoch: 152; Train loss: 0.3062612206394653; Dev loss: 0.80637548828125; (train.py:98)
[INFO] 2017-05-21T11:24:31+0800: Evaluation: (50, 450, 0.1) (train.py:102)
[INFO] 2017-05-21T11:28:11+0800: Epoch: 153; Train loss: 0.3041705100373439; Dev loss: 1.1745400390625; (train.py:98)
[INFO] 2017-05-21T11:31:52+0800: Epoch: 154; Train loss: 0.3054808599762095; Dev loss: 0.8125015869140625; (train.py:98)
[INFO] 2017-05-21T11:33:03+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T11:36:43+0800: Epoch: 155; Train loss: 0.30849597309745497; Dev loss: 0.7974080200195313; (train.py:98)
[INFO] 2017-05-21T11:40:25+0800: Epoch: 156; Train loss: 0.30771381515888047; Dev loss: 1.35976611328125; (train.py:98)
[INFO] 2017-05-21T11:41:29+0800: Evaluation: (34, 466, 0.068) (train.py:102)
[INFO] 2017-05-21T11:45:12+0800: Epoch: 157; Train loss: 0.3050770087516783; Dev loss: 0.3147069091796875; (train.py:98)
[INFO] 2017-05-21T11:48:52+0800: Epoch: 158; Train loss: 0.3097609042355757; Dev loss: 1.0215568237304689; (train.py:98)
[INFO] 2017-05-21T11:50:06+0800: Evaluation: (62, 438, 0.124) (train.py:102)
[INFO] 2017-05-21T11:53:46+0800: Epoch: 159; Train loss: 0.30492022353938686; Dev loss: 0.6608187255859375; (train.py:98)
[INFO] 2017-05-21T11:57:26+0800: Epoch: 160; Train loss: 0.31539321424749955; Dev loss: 0.8450986328125; (train.py:98)
[INFO] 2017-05-21T11:58:37+0800: Evaluation: (39, 461, 0.078) (train.py:102)
[INFO] 2017-05-21T12:02:18+0800: Epoch: 161; Train loss: 0.3120209758208174; Dev loss: 0.62083349609375; (train.py:98)
[INFO] 2017-05-21T12:06:00+0800: Epoch: 162; Train loss: 0.3088631079500691; Dev loss: 0.8024421997070312; (train.py:98)
[INFO] 2017-05-21T12:07:13+0800: Evaluation: (54, 446, 0.108) (train.py:102)
[INFO] 2017-05-21T12:10:54+0800: Epoch: 163; Train loss: 0.30396859776571855; Dev loss: 0.5336024169921875; (train.py:98)
[INFO] 2017-05-21T12:14:35+0800: Epoch: 164; Train loss: 0.30714883680749483; Dev loss: 1.2112598876953125; (train.py:98)
[INFO] 2017-05-21T12:15:47+0800: Evaluation: (62, 438, 0.124) (train.py:102)
[INFO] 2017-05-21T12:19:28+0800: Epoch: 165; Train loss: 0.30340016565766187; Dev loss: 1.360861328125; (train.py:98)
[INFO] 2017-05-21T12:23:09+0800: Epoch: 166; Train loss: 0.30721861841289616; Dev loss: 1.155552490234375; (train.py:98)
[INFO] 2017-05-21T12:24:20+0800: Evaluation: (50, 450, 0.1) (train.py:102)
[INFO] 2017-05-21T12:28:02+0800: Epoch: 167; Train loss: 0.3061542696357866; Dev loss: 0.7679722290039063; (train.py:98)
[INFO] 2017-05-21T12:31:42+0800: Epoch: 168; Train loss: 0.30320346465888826; Dev loss: 0.42794000244140623; (train.py:98)
[INFO] 2017-05-21T12:33:00+0800: Evaluation: (66, 434, 0.132) (train.py:102)
[INFO] 2017-05-21T12:36:41+0800: Epoch: 169; Train loss: 0.3056932479570308; Dev loss: 0.7487642822265625; (train.py:98)
[INFO] 2017-05-21T12:40:21+0800: Epoch: 170; Train loss: 0.306084800519054; Dev loss: 0.9227999267578125; (train.py:98)
[INFO] 2017-05-21T12:41:32+0800: Evaluation: (60, 440, 0.12) (train.py:102)
[INFO] 2017-05-21T12:45:11+0800: Epoch: 171; Train loss: 0.31202373228192687; Dev loss: 0.6996183471679688; (train.py:98)
[INFO] 2017-05-21T12:48:52+0800: Epoch: 172; Train loss: 0.31174843609305714; Dev loss: 0.7781143798828125; (train.py:98)
[INFO] 2017-05-21T12:50:07+0800: Evaluation: (64, 436, 0.128) (train.py:102)
[INFO] 2017-05-21T12:53:48+0800: Epoch: 173; Train loss: 0.30473379904531883; Dev loss: 0.8805274658203125; (train.py:98)
[INFO] 2017-05-21T12:57:29+0800: Epoch: 174; Train loss: 0.30766257358552723; Dev loss: 1.123248046875; (train.py:98)
[INFO] 2017-05-21T12:58:34+0800: Evaluation: (44, 456, 0.088) (train.py:102)
[INFO] 2017-05-21T13:02:14+0800: Epoch: 175; Train loss: 0.3040991042936847; Dev loss: 0.6534012451171874; (train.py:98)
[INFO] 2017-05-21T13:05:56+0800: Epoch: 176; Train loss: 0.3052155605235496; Dev loss: 1.0220596313476562; (train.py:98)
[INFO] 2017-05-21T13:07:10+0800: Evaluation: (56, 444, 0.112) (train.py:102)
[INFO] 2017-05-21T13:10:49+0800: Epoch: 177; Train loss: 0.3111186245869282; Dev loss: 0.45762258911132814; (train.py:98)
[INFO] 2017-05-21T13:14:29+0800: Epoch: 178; Train loss: 0.30382814826997834; Dev loss: 1.081156494140625; (train.py:98)
[INFO] 2017-05-21T13:15:40+0800: Evaluation: (54, 446, 0.108) (train.py:102)
[INFO] 2017-05-21T13:19:20+0800: Epoch: 179; Train loss: 0.3054745819465901; Dev loss: 0.8608425903320313; (train.py:98)
[INFO] 2017-05-21T13:23:02+0800: Epoch: 180; Train loss: 0.3070328049171032; Dev loss: 1.0308450927734376; (train.py:98)
[INFO] 2017-05-21T13:24:15+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-21T13:27:55+0800: Epoch: 181; Train loss: 0.306956951759705; Dev loss: 1.0280858154296875; (train.py:98)
[INFO] 2017-05-21T13:31:36+0800: Epoch: 182; Train loss: 0.3117966551709921; Dev loss: 0.8048250732421875; (train.py:98)
[INFO] 2017-05-21T13:32:52+0800: Evaluation: (65, 435, 0.13) (train.py:102)
[INFO] 2017-05-21T13:36:34+0800: Epoch: 183; Train loss: 0.30405645483969435; Dev loss: 0.5748892822265625; (train.py:98)
[INFO] 2017-05-21T13:40:12+0800: Epoch: 184; Train loss: 0.3079566814642073; Dev loss: 1.2169268798828126; (train.py:98)
[INFO] 2017-05-21T13:41:26+0800: Evaluation: (52, 448, 0.104) (train.py:102)
[INFO] 2017-05-21T13:45:06+0800: Epoch: 185; Train loss: 0.30602721600020666; Dev loss: 0.5408966674804687; (train.py:98)
[INFO] 2017-05-21T13:48:46+0800: Epoch: 186; Train loss: 0.30766476956364225; Dev loss: 0.9033037719726562; (train.py:98)
[INFO] 2017-05-21T13:50:00+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T13:53:39+0800: Epoch: 187; Train loss: 0.30125566423927624; Dev loss: 0.7706171875; (train.py:98)
[INFO] 2017-05-21T13:57:18+0800: Epoch: 188; Train loss: 0.31028037725025265; Dev loss: 0.931247802734375; (train.py:98)
[INFO] 2017-05-21T13:58:27+0800: Evaluation: (51, 449, 0.102) (train.py:102)
[INFO] 2017-05-21T14:02:07+0800: Epoch: 189; Train loss: 0.30760093336421435; Dev loss: 0.5312796630859375; (train.py:98)
[INFO] 2017-05-21T14:05:48+0800: Epoch: 190; Train loss: 0.3106120171349891; Dev loss: 0.9792092895507812; (train.py:98)
[INFO] 2017-05-21T14:06:54+0800: Evaluation: (42, 458, 0.084) (train.py:102)
[INFO] 2017-05-21T14:10:35+0800: Epoch: 191; Train loss: 0.30380496230595566; Dev loss: 1.160631591796875; (train.py:98)
[INFO] 2017-05-21T14:14:16+0800: Epoch: 192; Train loss: 0.310874557916162; Dev loss: 0.9673245239257813; (train.py:98)
[INFO] 2017-05-21T14:15:27+0800: Evaluation: (54, 446, 0.108) (train.py:102)
[INFO] 2017-05-21T14:19:08+0800: Epoch: 193; Train loss: 0.3088536595298914; Dev loss: 0.6464424438476563; (train.py:98)
[INFO] 2017-05-21T14:22:48+0800: Epoch: 194; Train loss: 0.3128049761614321; Dev loss: 0.8601908569335938; (train.py:98)
[INFO] 2017-05-21T14:24:04+0800: Evaluation: (70, 430, 0.14) (train.py:102)
[INFO] 2017-05-21T14:27:45+0800: Epoch: 195; Train loss: 0.30703278201637857; Dev loss: 0.6883350830078125; (train.py:98)
[INFO] 2017-05-21T14:31:26+0800: Epoch: 196; Train loss: 0.30910610584297576; Dev loss: 1.3426728515625; (train.py:98)
[INFO] 2017-05-21T14:32:37+0800: Evaluation: (47, 453, 0.094) (train.py:102)
[INFO] 2017-05-21T14:36:18+0800: Epoch: 197; Train loss: 0.30466165823726116; Dev loss: 0.6487178955078124; (train.py:98)
[INFO] 2017-05-21T14:39:59+0800: Epoch: 198; Train loss: 0.3069028841833667; Dev loss: 0.9227933349609375; (train.py:98)
[INFO] 2017-05-21T14:41:06+0800: Evaluation: (38, 462, 0.076) (train.py:102)
[INFO] 2017-05-21T14:44:48+0800: Epoch: 199; Train loss: 0.302024345028943; Dev loss: 0.4608438415527344; (train.py:98)
[INFO] 2017-05-21T14:48:30+0800: Epoch: 200; Train loss: 0.3109417995936385; Dev loss: 0.8419953002929688; (train.py:98)
[INFO] 2017-05-21T14:49:44+0800: Evaluation: (43, 457, 0.086) (train.py:102)
[INFO] 2017-05-21T14:53:23+0800: Epoch: 201; Train loss: 0.31115303801352057; Dev loss: 0.6647215576171875; (train.py:98)
[INFO] 2017-05-21T14:57:06+0800: Epoch: 202; Train loss: 0.31095564570471684; Dev loss: 1.456231201171875; (train.py:98)
[INFO] 2017-05-21T14:58:11+0800: Evaluation: (50, 450, 0.1) (train.py:102)
[INFO] 2017-05-21T15:01:54+0800: Epoch: 203; Train loss: 0.30659441253139386; Dev loss: 0.6003209228515625; (train.py:98)
[INFO] 2017-05-21T15:05:34+0800: Epoch: 204; Train loss: 0.3086988978089703; Dev loss: 0.66111279296875; (train.py:98)
[INFO] 2017-05-21T15:06:42+0800: Evaluation: (46, 454, 0.092) (train.py:102)
[INFO] 2017-05-21T15:10:24+0800: Epoch: 205; Train loss: 0.3042676154090288; Dev loss: 0.45097988891601565; (train.py:98)
[INFO] 2017-05-21T15:14:06+0800: Epoch: 206; Train loss: 0.3083281698887446; Dev loss: 1.446695068359375; (train.py:98)
[INFO] 2017-05-21T15:15:16+0800: Evaluation: (42, 458, 0.084) (train.py:102)
[INFO] 2017-05-21T15:18:56+0800: Epoch: 207; Train loss: 0.31165589808155664; Dev loss: 0.4036023254394531; (train.py:98)
[INFO] 2017-05-21T15:22:37+0800: Epoch: 208; Train loss: 0.30862624273550043; Dev loss: 1.1345711669921874; (train.py:98)
[INFO] 2017-05-21T15:23:46+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-21T15:27:25+0800: Epoch: 209; Train loss: 0.3072108056978504; Dev loss: 0.29573150634765627; (train.py:98)
[INFO] 2017-05-21T15:31:05+0800: Epoch: 210; Train loss: 0.30638234791576385; Dev loss: 0.6826025390625; (train.py:98)
[INFO] 2017-05-21T15:32:09+0800: Evaluation: (38, 462, 0.076) (train.py:102)
[INFO] 2017-05-21T15:35:50+0800: Epoch: 211; Train loss: 0.3075305842702457; Dev loss: 0.8641724243164063; (train.py:98)
[INFO] 2017-05-21T15:39:32+0800: Epoch: 212; Train loss: 0.3084008727345223; Dev loss: 0.833514892578125; (train.py:98)
[INFO] 2017-05-21T15:40:39+0800: Evaluation: (35, 465, 0.07) (train.py:102)
[INFO] 2017-05-21T15:44:18+0800: Epoch: 213; Train loss: 0.30841964643761516; Dev loss: 0.6318035888671875; (train.py:98)
[INFO] 2017-05-21T15:47:59+0800: Epoch: 214; Train loss: 0.30739298302283163; Dev loss: 0.9931114501953126; (train.py:98)
[INFO] 2017-05-21T15:49:14+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T15:52:54+0800: Epoch: 215; Train loss: 0.3103453339263532; Dev loss: 0.6218273315429688; (train.py:98)
[INFO] 2017-05-21T15:56:33+0800: Epoch: 216; Train loss: 0.30843442129233056; Dev loss: 1.082537109375; (train.py:98)
[INFO] 2017-05-21T15:57:42+0800: Evaluation: (44, 456, 0.088) (train.py:102)
[INFO] 2017-05-21T16:01:23+0800: Epoch: 217; Train loss: 0.3059982830952101; Dev loss: 0.4961630554199219; (train.py:98)
[INFO] 2017-05-21T16:05:04+0800: Epoch: 218; Train loss: 0.3051762343300708; Dev loss: 0.9734353637695312; (train.py:98)
[INFO] 2017-05-21T16:06:16+0800: Evaluation: (51, 449, 0.102) (train.py:102)
[INFO] 2017-05-21T16:09:55+0800: Epoch: 219; Train loss: 0.30827750067645904; Dev loss: 0.7187686157226563; (train.py:98)
[INFO] 2017-05-21T16:13:37+0800: Epoch: 220; Train loss: 0.30138341518459916; Dev loss: 1.1103599853515624; (train.py:98)
[INFO] 2017-05-21T16:14:49+0800: Evaluation: (54, 446, 0.108) (train.py:102)
[INFO] 2017-05-21T16:18:30+0800: Epoch: 221; Train loss: 0.3089830504262885; Dev loss: 1.0028704833984374; (train.py:98)
[INFO] 2017-05-21T16:22:11+0800: Epoch: 222; Train loss: 0.31091535240571294; Dev loss: 1.07645556640625; (train.py:98)
[INFO] 2017-05-21T16:23:20+0800: Evaluation: (53, 447, 0.106) (train.py:102)
[INFO] 2017-05-21T16:27:01+0800: Epoch: 223; Train loss: 0.3084138846294037; Dev loss: 0.7739035034179688; (train.py:98)
[INFO] 2017-05-21T16:30:43+0800: Epoch: 224; Train loss: 0.30759554869254835; Dev loss: 1.7205770263671876; (train.py:98)
[INFO] 2017-05-21T16:31:48+0800: Evaluation: (31, 469, 0.062) (train.py:102)
[INFO] 2017-05-21T16:35:29+0800: Epoch: 225; Train loss: 0.3050912366525995; Dev loss: 0.4435943298339844; (train.py:98)
[INFO] 2017-05-21T16:39:09+0800: Epoch: 226; Train loss: 0.3145596486316465; Dev loss: 0.7415398559570312; (train.py:98)
[INFO] 2017-05-21T16:40:21+0800: Evaluation: (46, 454, 0.092) (train.py:102)
[INFO] 2017-05-21T16:44:03+0800: Epoch: 227; Train loss: 0.30906308992694037; Dev loss: 1.2706031494140626; (train.py:98)
[INFO] 2017-05-21T16:47:44+0800: Epoch: 228; Train loss: 0.3125201833012376; Dev loss: 0.700955078125; (train.py:98)
[INFO] 2017-05-21T16:48:55+0800: Evaluation: (53, 447, 0.106) (train.py:102)
[INFO] 2017-05-21T16:52:36+0800: Epoch: 229; Train loss: 0.3042989011011886; Dev loss: 0.5970562133789062; (train.py:98)
[INFO] 2017-05-21T16:56:17+0800: Epoch: 230; Train loss: 0.30270681487171064; Dev loss: 0.55145751953125; (train.py:98)
[INFO] 2017-05-21T16:57:26+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-21T17:01:07+0800: Epoch: 231; Train loss: 0.3087934462068935; Dev loss: 1.0722984619140625; (train.py:98)
[INFO] 2017-05-21T17:04:46+0800: Epoch: 232; Train loss: 0.31098349873109604; Dev loss: 1.1380009765625; (train.py:98)
[INFO] 2017-05-21T17:05:56+0800: Evaluation: (46, 454, 0.092) (train.py:102)
[INFO] 2017-05-21T17:09:38+0800: Epoch: 233; Train loss: 0.3155146654667121; Dev loss: 0.32679989624023437; (train.py:98)
[INFO] 2017-05-21T17:13:21+0800: Epoch: 234; Train loss: 0.3098634234659177; Dev loss: 0.7307977294921875; (train.py:98)
[INFO] 2017-05-21T17:14:36+0800: Evaluation: (55, 445, 0.11) (train.py:102)
[INFO] 2017-05-21T17:18:16+0800: Epoch: 235; Train loss: 0.3067665851968157; Dev loss: 0.548530517578125; (train.py:98)
[INFO] 2017-05-21T17:21:59+0800: Epoch: 236; Train loss: 0.31110788006977; Dev loss: 0.8340511474609374; (train.py:98)
[INFO] 2017-05-21T17:23:04+0800: Evaluation: (36, 464, 0.072) (train.py:102)
[INFO] 2017-05-21T17:26:46+0800: Epoch: 237; Train loss: 0.3071564759821467; Dev loss: 1.239198974609375; (train.py:98)
[INFO] 2017-05-21T17:30:27+0800: Epoch: 238; Train loss: 0.30964377755471395; Dev loss: 0.9198806762695313; (train.py:98)
[INFO] 2017-05-21T17:31:36+0800: Evaluation: (45, 455, 0.09) (train.py:102)
[INFO] 2017-05-21T17:35:18+0800: Epoch: 239; Train loss: 0.30865927484405975; Dev loss: 0.40796231079101564; (train.py:98)
[INFO] 2017-05-21T17:38:57+0800: Epoch: 240; Train loss: 0.3084270571767916; Dev loss: 1.18866455078125; (train.py:98)
[INFO] 2017-05-21T17:40:08+0800: Evaluation: (57, 443, 0.114) (train.py:102)
[INFO] 2017-05-21T17:43:48+0800: Epoch: 241; Train loss: 0.3088653755163063; Dev loss: 0.5155573120117187; (train.py:98)
[INFO] 2017-05-21T17:47:29+0800: Epoch: 242; Train loss: 0.3147199800062257; Dev loss: 0.9158814697265625; (train.py:98)
[INFO] 2017-05-21T17:48:41+0800: Evaluation: (59, 441, 0.118) (train.py:102)
[INFO] 2017-05-21T17:52:22+0800: Epoch: 243; Train loss: 0.3076484545252053; Dev loss: 1.342351806640625; (train.py:98)
[INFO] 2017-05-21T17:56:03+0800: Epoch: 244; Train loss: 0.3129465330090196; Dev loss: 1.100606201171875; (train.py:98)
[INFO] 2017-05-21T17:57:14+0800: Evaluation: (45, 455, 0.09) (train.py:102)
[INFO] 2017-05-21T18:00:57+0800: Epoch: 245; Train loss: 0.3090436870870665; Dev loss: 0.42445419311523436; (train.py:98)
[INFO] 2017-05-21T18:04:37+0800: Epoch: 246; Train loss: 0.3097364019922937; Dev loss: 0.8185853271484375; (train.py:98)
[INFO] 2017-05-21T18:05:52+0800: Evaluation: (38, 462, 0.076) (train.py:102)
[INFO] 2017-05-21T18:09:33+0800: Epoch: 247; Train loss: 0.3107078259384784; Dev loss: 0.7351181030273437; (train.py:98)
[INFO] 2017-05-21T18:13:15+0800: Epoch: 248; Train loss: 0.3078046928381444; Dev loss: 0.9771654052734375; (train.py:98)
[INFO] 2017-05-21T18:14:30+0800: Evaluation: (58, 442, 0.116) (train.py:102)
[INFO] 2017-05-21T18:18:12+0800: Epoch: 249; Train loss: 0.30491157384171763; Dev loss: 0.5764498291015625; (train.py:98)
[INFO] 2017-05-21T18:21:53+0800: Epoch: 250; Train loss: 0.31080103975026674; Dev loss: 0.8203699951171874; (train.py:98)
[INFO] 2017-05-21T18:22:58+0800: Evaluation: (53, 447, 0.106) (train.py:102)
[INFO] 2017-05-21T18:26:39+0800: Epoch: 251; Train loss: 0.31111925653074635; Dev loss: 0.9470816040039063; (train.py:98)
[INFO] 2017-05-21T18:30:20+0800: Epoch: 252; Train loss: 0.3060141293430486; Dev loss: 0.7368698120117188; (train.py:98)
[INFO] 2017-05-21T18:31:27+0800: Evaluation: (53, 447, 0.106) (train.py:102)
[INFO] 2017-05-21T18:35:07+0800: Epoch: 253; Train loss: 0.30515951832246385; Dev loss: 1.3368072509765625; (train.py:98)
[INFO] 2017-05-21T18:38:49+0800: Epoch: 254; Train loss: 0.3184919045961057; Dev loss: 1.0524462890625; (train.py:98)
[INFO] 2017-05-21T18:39:48+0800: Evaluation: (30, 470, 0.06) (train.py:102)
[INFO] 2017-05-21T18:43:30+0800: Epoch: 255; Train loss: 0.3082597526253864; Dev loss: 0.5449146728515625; (train.py:98)
[INFO] 2017-05-21T18:47:12+0800: Epoch: 256; Train loss: 0.3135152368171883; Dev loss: 1.0467994384765624; (train.py:98)
[INFO] 2017-05-21T18:48:17+0800: Evaluation: (38, 462, 0.076) (train.py:102)
[INFO] 2017-05-21T18:51:59+0800: Epoch: 257; Train loss: 0.3105055588880941; Dev loss: 1.082124755859375; (train.py:98)
[INFO] 2017-05-21T18:55:41+0800: Epoch: 258; Train loss: 0.3119398659315706; Dev loss: 0.48122994995117185; (train.py:98)
[INFO] 2017-05-21T18:56:53+0800: Evaluation: (56, 444, 0.112) (train.py:102)
[INFO] 2017-05-21T19:00:33+0800: Epoch: 259; Train loss: 0.3049688467772743; Dev loss: 0.5507644653320313; (train.py:98)
[INFO] 2017-05-21T19:04:15+0800: Epoch: 260; Train loss: 0.3099775338592308; Dev loss: 1.063930908203125; (train.py:98)
[INFO] 2017-05-21T19:05:22+0800: Evaluation: (40, 460, 0.08) (train.py:102)
[INFO] 2017-05-21T19:09:04+0800: Epoch: 261; Train loss: 0.3127447351364537; Dev loss: 0.7267894287109375; (train.py:98)
[INFO] 2017-05-21T19:12:45+0800: Epoch: 262; Train loss: 0.3110269273814454; Dev loss: 0.6522152099609375; (train.py:98)
[INFO] 2017-05-21T19:13:51+0800: Evaluation: (35, 465, 0.07) (train.py:102)
[INFO] 2017-05-21T19:17:33+0800: Epoch: 263; Train loss: 0.30481355795996534; Dev loss: 0.5484609375; (train.py:98)
[INFO] 2017-05-21T19:21:15+0800: Epoch: 264; Train loss: 0.30721917331634735; Dev loss: 0.7776046142578125; (train.py:98)
[INFO] 2017-05-21T19:22:20+0800: Evaluation: (36, 464, 0.072) (train.py:102)
[INFO] 2017-05-21T19:26:03+0800: Epoch: 265; Train loss: 0.30584528941535183; Dev loss: 0.517262939453125; (train.py:98)
[INFO] 2017-05-21T19:29:43+0800: Epoch: 266; Train loss: 0.30646786537870385; Dev loss: 1.320230224609375; (train.py:98)
[INFO] 2017-05-21T19:30:50+0800: Evaluation: (51, 449, 0.102) (train.py:102)
[INFO] 2017-05-21T19:34:29+0800: Epoch: 267; Train loss: 0.3096065624520257; Dev loss: 0.978169677734375; (train.py:98)
[INFO] 2017-05-21T19:38:10+0800: Epoch: 268; Train loss: 0.308408934939317; Dev loss: 1.07705322265625; (train.py:98)
[INFO] 2017-05-21T19:39:14+0800: Evaluation: (36, 464, 0.072) (train.py:102)
[INFO] 2017-05-21T19:42:56+0800: Epoch: 269; Train loss: 0.30741090917308267; Dev loss: 0.5192536010742187; (train.py:98)
[INFO] 2017-05-21T19:46:38+0800: Epoch: 270; Train loss: 0.3184535838998013; Dev loss: 1.25618017578125; (train.py:98)
[INFO] 2017-05-21T19:47:42+0800: Evaluation: (41, 459, 0.082) (train.py:102)
[INFO] 2017-05-21T19:51:25+0800: Epoch: 271; Train loss: 0.30960528511989266; Dev loss: 1.1467723388671875; (train.py:98)
[INFO] 2017-05-21T19:55:07+0800: Epoch: 272; Train loss: 0.31643900869739067; Dev loss: 0.9290477905273438; (train.py:98)
[INFO] 2017-05-21T19:56:05+0800: Evaluation: (44, 456, 0.088) (train.py:102)
[INFO] 2017-05-21T19:59:48+0800: Epoch: 273; Train loss: 0.31382435056997726; Dev loss: 1.0085938110351562; (train.py:98)
[INFO] 2017-05-21T20:03:30+0800: Epoch: 274; Train loss: 0.31386048885720513; Dev loss: 0.9387367553710938; (train.py:98)
[INFO] 2017-05-21T20:04:41+0800: Evaluation: (64, 436, 0.128) (train.py:102)
[INFO] 2017-05-21T20:08:23+0800: Epoch: 275; Train loss: 0.3071753890620308; Dev loss: 0.46647998046875; (train.py:98)
[INFO] 2017-05-21T20:12:06+0800: Epoch: 276; Train loss: 0.306671136154902; Dev loss: 0.5838389892578125; (train.py:98)
[INFO] 2017-05-21T20:13:07+0800: Evaluation: (38, 462, 0.076) (train.py:102)
[INFO] 2017-05-21T20:16:49+0800: Epoch: 277; Train loss: 0.3055827017550681; Dev loss: 1.4467210693359376; (train.py:98)
[INFO] 2017-05-21T20:20:31+0800: Epoch: 278; Train loss: 0.3082793027856775; Dev loss: 1.11289892578125; (train.py:98)
[INFO] 2017-05-21T20:21:41+0800: Evaluation: (56, 444, 0.112) (train.py:102)
[INFO] 2017-05-21T20:25:23+0800: Epoch: 279; Train loss: 0.30665344256258154; Dev loss: 0.83794384765625; (train.py:98)
[INFO] 2017-05-21T20:29:05+0800: Epoch: 280; Train loss: 0.3084690767606499; Dev loss: 1.182865966796875; (train.py:98)
[INFO] 2017-05-21T20:30:12+0800: Evaluation: (35, 465, 0.07) (train.py:102)
[INFO] 2017-05-21T20:33:53+0800: Epoch: 281; Train loss: 0.3091311485529601; Dev loss: 0.71167333984375; (train.py:98)
[INFO] 2017-05-21T20:37:32+0800: Epoch: 282; Train loss: 0.3191452591293541; Dev loss: 1.3022794189453124; (train.py:98)
[INFO] 2017-05-21T20:38:39+0800: Evaluation: (34, 466, 0.068) (train.py:102)
[INFO] 2017-05-21T20:42:20+0800: Epoch: 283; Train loss: 0.31086610552482324; Dev loss: 0.74598583984375; (train.py:98)
[INFO] 2017-05-21T20:46:00+0800: Epoch: 284; Train loss: 0.311317641318557; Dev loss: 1.109213623046875; (train.py:98)
[INFO] 2017-05-21T20:47:14+0800: Evaluation: (41, 459, 0.082) (train.py:102)
[INFO] 2017-05-21T20:50:55+0800: Epoch: 285; Train loss: 0.3124503351481693; Dev loss: 1.0207841796875; (train.py:98)
[INFO] 2017-05-21T20:54:35+0800: Epoch: 286; Train loss: 0.30858061182123714; Dev loss: 0.7498667602539062; (train.py:98)
[INFO] 2017-05-21T20:55:49+0800: Evaluation: (60, 440, 0.12) (train.py:102)
[INFO] 2017-05-21T20:59:29+0800: Epoch: 287; Train loss: 0.303154655343123; Dev loss: 0.799084228515625; (train.py:98)
[INFO] 2017-05-21T21:03:09+0800: Epoch: 288; Train loss: 0.312880381169902; Dev loss: 1.157509765625; (train.py:98)
[INFO] 2017-05-21T21:04:10+0800: Evaluation: (25, 475, 0.05) (train.py:102)
[INFO] 2017-05-21T21:07:49+0800: Epoch: 289; Train loss: 0.3118926853848577; Dev loss: 0.5299791870117188; (train.py:98)
[INFO] 2017-05-21T21:11:30+0800: Epoch: 290; Train loss: 0.3124020927302833; Dev loss: 0.8327991943359375; (train.py:98)
[INFO] 2017-05-21T21:12:43+0800: Evaluation: (48, 452, 0.096) (train.py:102)
[INFO] 2017-05-21T21:16:23+0800: Epoch: 291; Train loss: 0.3097593443828913; Dev loss: 0.35080279541015624; (train.py:98)
[INFO] 2017-05-21T21:20:03+0800: Epoch: 292; Train loss: 0.3126900097179703; Dev loss: 1.60471923828125; (train.py:98)
[INFO] 2017-05-21T21:21:10+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-21T21:24:51+0800: Epoch: 293; Train loss: 0.30738606526803286; Dev loss: 0.6222235717773438; (train.py:98)
[INFO] 2017-05-21T21:28:32+0800: Epoch: 294; Train loss: 0.3124842576020042; Dev loss: 0.9430800170898438; (train.py:98)
[INFO] 2017-05-21T21:29:43+0800: Evaluation: (48, 452, 0.096) (train.py:102)
[INFO] 2017-05-21T21:33:24+0800: Epoch: 295; Train loss: 0.31181661734424904; Dev loss: 0.754038818359375; (train.py:98)
[INFO] 2017-05-21T21:37:04+0800: Epoch: 296; Train loss: 0.31402701653591514; Dev loss: 0.71925244140625; (train.py:98)
[INFO] 2017-05-21T21:38:12+0800: Evaluation: (48, 452, 0.096) (train.py:102)
[INFO] 2017-05-21T21:41:54+0800: Epoch: 297; Train loss: 0.31382514055997235; Dev loss: 0.38125894165039065; (train.py:98)
[INFO] 2017-05-21T21:45:35+0800: Epoch: 298; Train loss: 0.31793285747513955; Dev loss: 1.15935302734375; (train.py:98)
[INFO] 2017-05-21T21:46:39+0800: Evaluation: (39, 461, 0.078) (train.py:102)
[INFO] 2017-05-21T21:50:21+0800: Epoch: 299; Train loss: 0.30997002049119116; Dev loss: 0.7412823486328125; (train.py:98)
[INFO] 2017-05-21T21:54:02+0800: Epoch: 300; Train loss: 0.31350355205442204; Dev loss: 1.0511256103515625; (train.py:98)
[INFO] 2017-05-21T21:55:13+0800: Evaluation: (46, 454, 0.092) (train.py:102)
[INFO] 2017-05-21T21:58:55+0800: Epoch: 301; Train loss: 0.31370614916093287; Dev loss: 1.066112548828125; (train.py:98)
[INFO] 2017-05-21T22:02:37+0800: Epoch: 302; Train loss: 0.31335983735624073; Dev loss: 0.6951325073242187; (train.py:98)
[INFO] 2017-05-21T22:03:44+0800: Evaluation: (39, 461, 0.078) (train.py:102)
[INFO] 2017-05-21T22:07:25+0800: Epoch: 303; Train loss: 0.3103019346227168; Dev loss: 0.30929937744140623; (train.py:98)
[INFO] 2017-05-21T22:11:07+0800: Epoch: 304; Train loss: 0.30964205253158694; Dev loss: 1.3320107421875; (train.py:98)
[INFO] 2017-05-21T22:12:15+0800: Evaluation: (45, 455, 0.09) (train.py:102)
[INFO] 2017-05-21T22:15:59+0800: Epoch: 305; Train loss: 0.311076621966503; Dev loss: 1.336260009765625; (train.py:98)
[INFO] 2017-05-21T22:19:39+0800: Epoch: 306; Train loss: 0.3111599055713328; Dev loss: 0.68915869140625; (train.py:98)
[INFO] 2017-05-21T22:20:42+0800: Evaluation: (35, 465, 0.07) (train.py:102)
[INFO] 2017-05-21T22:24:23+0800: Epoch: 307; Train loss: 0.3119364468773694; Dev loss: 0.758367919921875; (train.py:98)
[INFO] 2017-05-21T22:28:03+0800: Epoch: 308; Train loss: 0.3135918606419114; Dev loss: 0.7483045654296875; (train.py:98)
[INFO] 2017-05-21T22:29:09+0800: Evaluation: (46, 454, 0.092) (train.py:102)
[INFO] 2017-05-21T22:32:50+0800: Epoch: 309; Train loss: 0.3090896442931435; Dev loss: 0.63689013671875; (train.py:98)
[INFO] 2017-05-21T22:36:29+0800: Epoch: 310; Train loss: 0.31482966147658786; Dev loss: 0.909560546875; (train.py:98)
[INFO] 2017-05-21T22:37:39+0800: Evaluation: (43, 457, 0.086) (train.py:102)
[INFO] 2017-05-21T22:41:21+0800: Epoch: 311; Train loss: 0.3157369541413933; Dev loss: 0.7025255126953125; (train.py:98)
[INFO] 2017-05-21T22:45:03+0800: Epoch: 312; Train loss: 0.3153789298342625; Dev loss: 0.765006103515625; (train.py:98)
[INFO] 2017-05-21T22:46:13+0800: Evaluation: (39, 461, 0.078) (train.py:102)
[INFO] 2017-05-21T22:49:53+0800: Epoch: 313; Train loss: 0.31098828474953827; Dev loss: 0.5985908203125; (train.py:98)
[INFO] 2017-05-21T22:53:33+0800: Epoch: 314; Train loss: 0.3138274693754381; Dev loss: 0.87929345703125; (train.py:98)
[INFO] 2017-05-21T22:54:37+0800: Evaluation: (37, 463, 0.074) (train.py:102)
[INFO] 2017-05-21T22:58:18+0800: Epoch: 315; Train loss: 0.3145217091419868; Dev loss: 2.114416015625; (train.py:98)
[INFO] 2017-05-21T23:01:59+0800: Epoch: 316; Train loss: 0.3129892119761863; Dev loss: 0.7667421875; (train.py:98)
[INFO] 2017-05-21T23:03:06+0800: Evaluation: (29, 471, 0.058) (train.py:102)
[INFO] 2017-05-21T23:06:48+0800: Epoch: 317; Train loss: 0.30918943635615037; Dev loss: 1.7747908935546874; (train.py:98)
[INFO] 2017-05-21T23:10:28+0800: Epoch: 318; Train loss: 0.3118003707547956; Dev loss: 0.8429868774414062; (train.py:98)
[INFO] 2017-05-21T23:11:42+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-21T23:15:24+0800: Epoch: 319; Train loss: 0.3078016186556286; Dev loss: 1.0026481323242187; (train.py:98)
[INFO] 2017-05-21T23:19:03+0800: Epoch: 320; Train loss: 0.3125326103983565; Dev loss: 0.8296500244140625; (train.py:98)
[INFO] 2017-05-21T23:20:08+0800: Evaluation: (45, 455, 0.09) (train.py:102)
[INFO] 2017-05-21T23:23:49+0800: Epoch: 321; Train loss: 0.3072828523795463; Dev loss: 0.6953867797851563; (train.py:98)
[INFO] 2017-05-21T23:27:31+0800: Epoch: 322; Train loss: 0.3089619805954831; Dev loss: 0.9685866088867188; (train.py:98)
[INFO] 2017-05-21T23:28:38+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-21T23:32:20+0800: Epoch: 323; Train loss: 0.3093276080328568; Dev loss: 0.2676439208984375; (train.py:98)
[INFO] 2017-05-21T23:36:00+0800: Epoch: 324; Train loss: 0.3095005064637951; Dev loss: 1.148341064453125; (train.py:98)
[INFO] 2017-05-21T23:37:04+0800: Evaluation: (41, 459, 0.082) (train.py:102)
[INFO] 2017-05-21T23:40:45+0800: Epoch: 325; Train loss: 0.3106202755675503; Dev loss: 0.5760758056640625; (train.py:98)
[INFO] 2017-05-21T23:44:26+0800: Epoch: 326; Train loss: 0.3129850285540997; Dev loss: 1.001078857421875; (train.py:98)
[INFO] 2017-05-21T23:45:33+0800: Evaluation: (44, 456, 0.088) (train.py:102)
[INFO] 2017-05-21T23:49:15+0800: Epoch: 327; Train loss: 0.31283246441364404; Dev loss: 0.7532700805664062; (train.py:98)
[INFO] 2017-05-21T23:52:56+0800: Epoch: 328; Train loss: 0.3127720150531193; Dev loss: 0.7358396606445312; (train.py:98)
[INFO] 2017-05-21T23:53:58+0800: Evaluation: (44, 456, 0.088) (train.py:102)
[INFO] 2017-05-21T23:57:40+0800: Epoch: 329; Train loss: 0.31205714813520136; Dev loss: 0.626712890625; (train.py:98)
[INFO] 2017-05-22T00:01:19+0800: Epoch: 330; Train loss: 0.30955770116077785; Dev loss: 1.2548349609375; (train.py:98)
[INFO] 2017-05-22T00:02:21+0800: Evaluation: (31, 469, 0.062) (train.py:102)
[INFO] 2017-05-22T00:06:02+0800: Epoch: 331; Train loss: 0.30807174439942253; Dev loss: 0.8128598022460938; (train.py:98)
[INFO] 2017-05-22T00:09:43+0800: Epoch: 332; Train loss: 0.3130825046069137; Dev loss: 1.102532958984375; (train.py:98)
[INFO] 2017-05-22T00:10:48+0800: Evaluation: (36, 464, 0.072) (train.py:102)
[INFO] 2017-05-22T00:14:28+0800: Epoch: 333; Train loss: 0.3110644471093308; Dev loss: 0.49971209716796877; (train.py:98)
[INFO] 2017-05-22T00:18:10+0800: Epoch: 334; Train loss: 0.3168150038074883; Dev loss: 0.8309305419921875; (train.py:98)
[INFO] 2017-05-22T00:19:18+0800: Evaluation: (43, 457, 0.086) (train.py:102)
[INFO] 2017-05-22T00:23:01+0800: Epoch: 335; Train loss: 0.3117323361339215; Dev loss: 0.8836318359375; (train.py:98)
[INFO] 2017-05-22T00:26:43+0800: Epoch: 336; Train loss: 0.3230218202542631; Dev loss: 0.9589837646484375; (train.py:98)
[INFO] 2017-05-22T00:27:57+0800: Evaluation: (61, 439, 0.122) (train.py:102)
[INFO] 2017-05-22T00:31:37+0800: Epoch: 337; Train loss: 0.309178204390687; Dev loss: 0.7394400634765625; (train.py:98)
[INFO] 2017-05-22T00:35:20+0800: Epoch: 338; Train loss: 0.309670561300421; Dev loss: 1.334379150390625; (train.py:98)
[INFO] 2017-05-22T00:36:25+0800: Evaluation: (35, 465, 0.07) (train.py:102)
[INFO] 2017-05-22T00:40:07+0800: Epoch: 339; Train loss: 0.31219465256584755; Dev loss: 0.8400985717773437; (train.py:98)
[INFO] 2017-05-22T00:43:48+0800: Epoch: 340; Train loss: 0.31484932659474374; Dev loss: 0.800009521484375; (train.py:98)
[INFO] 2017-05-22T00:44:50+0800: Evaluation: (43, 457, 0.086) (train.py:102)
[INFO] 2017-05-22T00:48:30+0800: Epoch: 341; Train loss: 0.3107969541863149; Dev loss: 0.4140389709472656; (train.py:98)
[INFO] 2017-05-22T00:52:10+0800: Epoch: 342; Train loss: 0.3138015734550355; Dev loss: 0.8369998779296876; (train.py:98)
[INFO] 2017-05-22T00:53:19+0800: Evaluation: (44, 456, 0.088) (train.py:102)
[INFO] 2017-05-22T00:56:58+0800: Epoch: 343; Train loss: 0.31144752845958334; Dev loss: 0.9459622802734375; (train.py:98)
[INFO] 2017-05-22T01:00:41+0800: Epoch: 344; Train loss: 0.31009931238645516; Dev loss: 1.177756591796875; (train.py:98)
[INFO] 2017-05-22T01:01:52+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-22T01:05:32+0800: Epoch: 345; Train loss: 0.31190100818952626; Dev loss: 0.6698815307617187; (train.py:98)
[INFO] 2017-05-22T01:09:14+0800: Epoch: 346; Train loss: 0.3167181935429309; Dev loss: 1.2321484375; (train.py:98)
[INFO] 2017-05-22T01:10:19+0800: Evaluation: (30, 470, 0.06) (train.py:102)
[INFO] 2017-05-22T01:14:00+0800: Epoch: 347; Train loss: 0.3151944021276437; Dev loss: 0.973198974609375; (train.py:98)
[INFO] 2017-05-22T01:17:41+0800: Epoch: 348; Train loss: 0.31442561338112524; Dev loss: 0.6394531860351562; (train.py:98)
[INFO] 2017-05-22T01:18:50+0800: Evaluation: (47, 453, 0.094) (train.py:102)
[INFO] 2017-05-22T01:22:33+0800: Epoch: 349; Train loss: 0.3090654557346489; Dev loss: 1.2652366943359374; (train.py:98)
[INFO] 2017-05-22T01:26:14+0800: Epoch: 350; Train loss: 0.3124366070613207; Dev loss: 1.051462158203125; (train.py:98)
[INFO] 2017-05-22T01:27:23+0800: Evaluation: (40, 460, 0.08) (train.py:102)
[INFO] 2017-05-22T01:31:04+0800: Epoch: 351; Train loss: 0.31284279960525535; Dev loss: 0.770565185546875; (train.py:98)
[INFO] 2017-05-22T01:34:46+0800: Epoch: 352; Train loss: 0.31256033690883583; Dev loss: 0.96858056640625; (train.py:98)
[INFO] 2017-05-22T01:35:54+0800: Evaluation: (43, 457, 0.086) (train.py:102)
[INFO] 2017-05-22T01:39:34+0800: Epoch: 353; Train loss: 0.31182767052497057; Dev loss: 1.0771763916015624; (train.py:98)
[INFO] 2017-05-22T01:43:16+0800: Epoch: 354; Train loss: 0.3148217824560752; Dev loss: 1.3151494140625; (train.py:98)
[INFO] 2017-05-22T01:44:31+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-22T01:48:11+0800: Epoch: 355; Train loss: 0.3130976243043885; Dev loss: 0.6882615966796874; (train.py:98)
[INFO] 2017-05-22T01:51:54+0800: Epoch: 356; Train loss: 0.31399437670732533; Dev loss: 0.86811181640625; (train.py:98)
[INFO] 2017-05-22T01:52:58+0800: Evaluation: (31, 469, 0.062) (train.py:102)
[INFO] 2017-05-22T01:56:40+0800: Epoch: 357; Train loss: 0.30935860600126475; Dev loss: 0.48306146240234377; (train.py:98)
[INFO] 2017-05-22T02:00:24+0800: Epoch: 358; Train loss: 0.3138924326627686; Dev loss: 1.04896142578125; (train.py:98)
[INFO] 2017-05-22T02:01:34+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-22T02:05:15+0800: Epoch: 359; Train loss: 0.31494458254181845; Dev loss: 0.7927453002929687; (train.py:98)
[INFO] 2017-05-22T02:08:55+0800: Epoch: 360; Train loss: 0.31463802974042565; Dev loss: 0.8784180297851563; (train.py:98)
[INFO] 2017-05-22T02:10:03+0800: Evaluation: (36, 464, 0.072) (train.py:102)
[INFO] 2017-05-22T02:13:45+0800: Epoch: 361; Train loss: 0.31854095651100983; Dev loss: 1.0937420654296874; (train.py:98)
[INFO] 2017-05-22T02:17:26+0800: Epoch: 362; Train loss: 0.31726640703448694; Dev loss: 0.9285880126953125; (train.py:98)
[INFO] 2017-05-22T02:18:36+0800: Evaluation: (48, 452, 0.096) (train.py:102)
[INFO] 2017-05-22T02:22:18+0800: Epoch: 363; Train loss: 0.3118832051969947; Dev loss: 0.9903184814453125; (train.py:98)
[INFO] 2017-05-22T02:26:01+0800: Epoch: 364; Train loss: 0.31318831251355583; Dev loss: 0.910185791015625; (train.py:98)
[INFO] 2017-05-22T02:27:01+0800: Evaluation: (20, 480, 0.04) (train.py:102)
[INFO] 2017-05-22T02:30:42+0800: Epoch: 365; Train loss: 0.31688353649838263; Dev loss: 0.743034912109375; (train.py:98)
[INFO] 2017-05-22T02:34:22+0800: Epoch: 366; Train loss: 0.31673451021840876; Dev loss: 0.7376190185546875; (train.py:98)
[INFO] 2017-05-22T02:35:32+0800: Evaluation: (45, 455, 0.09) (train.py:102)
[INFO] 2017-05-22T02:39:12+0800: Epoch: 367; Train loss: 0.31510246768059064; Dev loss: 0.4776445007324219; (train.py:98)
[INFO] 2017-05-22T02:42:54+0800: Epoch: 368; Train loss: 0.31527110749134085; Dev loss: 0.9185504760742188; (train.py:98)
[INFO] 2017-05-22T02:43:58+0800: Evaluation: (44, 456, 0.088) (train.py:102)
[INFO] 2017-05-22T02:47:40+0800: Epoch: 369; Train loss: 0.31031401720997015; Dev loss: 0.37252716064453123; (train.py:98)
[INFO] 2017-05-22T02:51:21+0800: Epoch: 370; Train loss: 0.31012382548396183; Dev loss: 1.206679443359375; (train.py:98)
[INFO] 2017-05-22T02:52:27+0800: Evaluation: (31, 469, 0.062) (train.py:102)
[INFO] 2017-05-22T02:56:04+0800: Epoch: 371; Train loss: 0.3067017247126353; Dev loss: 0.866686279296875; (train.py:98)
[INFO] 2017-05-22T02:59:46+0800: Epoch: 372; Train loss: 0.31505194555424204; Dev loss: 1.18811962890625; (train.py:98)
[INFO] 2017-05-22T03:00:57+0800: Evaluation: (42, 458, 0.084) (train.py:102)
[INFO] 2017-05-22T03:04:37+0800: Epoch: 373; Train loss: 0.31412470927379876; Dev loss: 0.4777047119140625; (train.py:98)
[INFO] 2017-05-22T03:08:19+0800: Epoch: 374; Train loss: 0.3152941590124551; Dev loss: 0.9542508544921875; (train.py:98)
[INFO] 2017-05-22T03:09:21+0800: Evaluation: (41, 459, 0.082) (train.py:102)
[INFO] 2017-05-22T03:13:02+0800: Epoch: 375; Train loss: 0.3135387518238347; Dev loss: 0.8674891357421874; (train.py:98)
[INFO] 2017-05-22T03:16:44+0800: Epoch: 376; Train loss: 0.313791460257377; Dev loss: 0.9775514526367187; (train.py:98)
[INFO] 2017-05-22T03:17:55+0800: Evaluation: (55, 445, 0.11) (train.py:102)
[INFO] 2017-05-22T03:21:35+0800: Epoch: 377; Train loss: 0.31416356968575837; Dev loss: 0.3626678466796875; (train.py:98)
[INFO] 2017-05-22T03:25:15+0800: Epoch: 378; Train loss: 0.31685165516815444; Dev loss: 0.6312173461914062; (train.py:98)
[INFO] 2017-05-22T03:26:18+0800: Evaluation: (28, 472, 0.056) (train.py:102)
[INFO] 2017-05-22T03:30:01+0800: Epoch: 379; Train loss: 0.3099015527328156; Dev loss: 1.0534603271484375; (train.py:98)
[INFO] 2017-05-22T03:33:42+0800: Epoch: 380; Train loss: 0.3102128409876394; Dev loss: 0.809874267578125; (train.py:98)
[INFO] 2017-05-22T03:34:50+0800: Evaluation: (49, 451, 0.098) (train.py:102)
[INFO] 2017-05-22T03:38:32+0800: Epoch: 381; Train loss: 0.30920985367939335; Dev loss: 0.5835592651367187; (train.py:98)
[INFO] 2017-05-22T03:42:14+0800: Epoch: 382; Train loss: 0.32043885779627956; Dev loss: 0.721252197265625; (train.py:98)
[INFO] 2017-05-22T03:43:11+0800: Evaluation: (29, 471, 0.058) (train.py:102)
[INFO] 2017-05-22T03:46:52+0800: Epoch: 383; Train loss: 0.3064880638223258; Dev loss: 0.812689453125; (train.py:98)
[INFO] 2017-05-22T03:50:33+0800: Epoch: 384; Train loss: 0.3108940696407678; Dev loss: 0.8099300537109375; (train.py:98)
[INFO] 2017-05-22T03:51:38+0800: Evaluation: (56, 444, 0.112) (train.py:102)
[INFO] 2017-05-22T03:55:19+0800: Epoch: 385; Train loss: 0.3139876595721559; Dev loss: 0.41554449462890625; (train.py:98)
[INFO] 2017-05-22T03:59:01+0800: Epoch: 386; Train loss: 0.3181396750044622; Dev loss: 1.13129443359375; (train.py:98)
[INFO] 2017-05-22T04:00:06+0800: Evaluation: (38, 462, 0.076) (train.py:102)
[INFO] 2017-05-22T04:03:47+0800: Epoch: 387; Train loss: 0.31475518622360354; Dev loss: 0.5349365844726562; (train.py:98)
[INFO] 2017-05-22T04:07:27+0800: Epoch: 388; Train loss: 0.3162046914707282; Dev loss: 0.7450342407226562; (train.py:98)
[INFO] 2017-05-22T04:08:38+0800: Evaluation: (45, 455, 0.09) (train.py:102)
[INFO] 2017-05-22T04:12:19+0800: Epoch: 389; Train loss: 0.3130962217015493; Dev loss: 0.69532275390625; (train.py:98)
[INFO] 2017-05-22T04:16:02+0800: Epoch: 390; Train loss: 0.31643762466405645; Dev loss: 1.3036802978515625; (train.py:98)
[INFO] 2017-05-22T04:17:03+0800: Evaluation: (27, 473, 0.054) (train.py:102)
[INFO] 2017-05-22T04:20:45+0800: Epoch: 391; Train loss: 0.3194408100525324; Dev loss: 0.6158151245117187; (train.py:98)
[INFO] 2017-05-22T04:24:26+0800: Epoch: 392; Train loss: 0.3131367056050755; Dev loss: 1.030863037109375; (train.py:98)
[INFO] 2017-05-22T04:25:26+0800: Evaluation: (22, 478, 0.044) (train.py:102)
[INFO] 2017-05-22T04:29:08+0800: Epoch: 393; Train loss: 0.3132075158541134; Dev loss: 0.84510400390625; (train.py:98)
[INFO] 2017-05-22T04:32:48+0800: Epoch: 394; Train loss: 0.3167888577882961; Dev loss: 1.2908653564453125; (train.py:98)
[INFO] 2017-05-22T04:33:57+0800: Evaluation: (51, 449, 0.102) (train.py:102)
[INFO] 2017-05-22T04:37:38+0800: Epoch: 395; Train loss: 0.30957436245224484; Dev loss: 0.8279375; (train.py:98)
[INFO] 2017-05-22T04:41:20+0800: Epoch: 396; Train loss: 0.31520444584937424; Dev loss: 1.429530517578125; (train.py:98)
[INFO] 2017-05-22T04:42:32+0800: Evaluation: (45, 455, 0.09) (train.py:102)
[INFO] 2017-05-22T04:46:13+0800: Epoch: 397; Train loss: 0.314068036422187; Dev loss: 0.6115785522460937; (train.py:98)
[INFO] 2017-05-22T04:49:54+0800: Epoch: 398; Train loss: 0.3146108822282137; Dev loss: 0.9605545654296875; (train.py:98)
[INFO] 2017-05-22T04:51:03+0800: Evaluation: (44, 456, 0.088) (train.py:102)
[INFO] 2017-05-22T04:54:44+0800: Epoch: 399; Train loss: 0.3116698472666093; Dev loss: 0.40482785034179686; (train.py:98)
